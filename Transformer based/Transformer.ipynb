{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HzETJPTeDI2l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import youtokentome as yttm\n",
    "from livelossplot import PlotLosses\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WaS0OXNbDI2v"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "cpu = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4swSGSVDI25"
   },
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTSxoD8cDI25"
   },
   "outputs": [],
   "source": [
    "story_path = \"corpus/story_data_punct_del_em.pkl\"\n",
    "with open(story_path, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iNrocaqPSifM"
   },
   "outputs": [],
   "source": [
    "STORY_VAL = 34000\n",
    "data_batch = data[:STORY_VAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples2text(data, story_size=300):\n",
    "    new_data = []\n",
    "    for i in range(len(data)):\n",
    "        text = \" \".join(data[i]).replace(\" .\",\".\").replace(\" ,\", \",\").replace(\" ?\", \"?\")\n",
    "        \n",
    "        if len(text) <= story_size:\n",
    "            new_data.append(text)\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch = list(samples2text(data_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'У нас в городе есть целое дерево, с верху до низа обвешанное кроссами Привет из Мытищ.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_story = np.random.randint(0, len(data_batch)-1)\n",
    "data_batch[random_story]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_tools import split_data, get_bpe_tokenizer, get_unknown_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 21061\n",
      "\n",
      "Traning size: 15795 | Validating size: 5266\n"
     ]
    }
   ],
   "source": [
    "train_texts, test_texts = split_data(data_batch, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply BPE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt = 'train_bpe.txt'\n",
    "bpe_model_name = \"story_bpe.yttm\"\n",
    "BPE_VOCAB_SIZE = 1000\n",
    "\n",
    "tokenizer = get_bpe_tokenizer(train_texts, train_txt_path=train_txt, bpe_model_name=bpe_model_name,\n",
    "                              vocab_size=BPE_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отчим рассказывал, как он воевал в Афганистане и там они жгли лазером духов блять, черножопых, как марсиане людей в Войне миров. за этого марсианина\n",
      "\n",
      "974 746 696 28 378 20 223 234 277 7 378 144 327 38 287 179 272 192 145 388 536 224 25 177 496 22 7 568 435 207 15 753 485 158 196 165 32 5 19 28 742 223 150 217 510 6 192 489 18 225 144 227 256 192 622 532 24 176 745 150 217 510 6 179 180\n"
     ]
    }
   ],
   "source": [
    "random_id = np.random.randint(1, len(train_texts)-1)\n",
    "\n",
    "print(train_texts[random_id])\n",
    "print(\"\")\n",
    "print(*tokenizer.encode(train_texts[random_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_token_ids = tokenizer.encode(train_texts, bos=True, eos=True)\n",
    "test_token_ids = tokenizer.encode(test_texts, bos=True, eos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown n-grams in validation set:  0\n"
     ]
    }
   ],
   "source": [
    "get_unknown_ngrams(test_token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data-loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(data, padding_value=0, batch_size=512, shuffle=True):\n",
    "    input_seq = []\n",
    "    target_seq = []\n",
    "    \n",
    "    for story in data:\n",
    "        input_seq.append(torch.tensor(story[:-1]))\n",
    "        target_seq.append(torch.tensor(story[1:]))\n",
    "    \n",
    "    input_seq = pad_sequence(input_seq, batch_first=True, padding_value=padding_value)\n",
    "    target_seq = pad_sequence(target_seq, batch_first=True, padding_value=padding_value)\n",
    "\n",
    "    data = torch.utils.data.TensorDataset(input_seq, target_seq)\n",
    "    data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loaders(train_token_ids)\n",
    "test_loader = get_loaders(test_token_ids, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Chp0UCPDDI3F"
   },
   "source": [
    "## Init Language Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_tools import dependency_mask, positional_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, backbone, emb_dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
    "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
    "        self.backbone = backbone\n",
    "        self.out = nn.Linear(embedding_size, vocab_size)\n",
    "    \n",
    "    def forward(self, seed_token_ids):\n",
    "\n",
    "        batch_size, max_in_length = seed_token_ids.shape\n",
    "\n",
    "        seed_padding_mask = seed_token_ids == 0\n",
    "        dep_mask = dependency_mask(max_in_length).to(seed_token_ids.device)\n",
    "        \n",
    "        seed_embs = self.embeddings(seed_token_ids)  \n",
    "        pos_codes = positional_encoding(max_in_length,\n",
    "                                             self.embedding_size).unsqueeze(0).to(seed_embs.device)\n",
    "        seed_embs = seed_embs + pos_codes\n",
    "        seed_embs = self.emb_dropout(seed_embs)\n",
    "\n",
    "        \n",
    "        target_features = seed_embs\n",
    "        target_features = self.backbone(seed_embs,\n",
    "                                        mask=dep_mask,\n",
    "                                        src_key_padding_mask=seed_padding_mask)\n",
    "        \n",
    "        logits = self.out(target_features)  \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for batch-first\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.impl = nn.TransformerEncoder(*args, **kwargs)\n",
    "        self.initialize_weights()\n",
    "    \n",
    "    def forward(self, src, *args, **kwargs):\n",
    "        src = src.transpose(0, 1).contiguous()  \n",
    "        result = self.impl(src, *args, **kwargs)  \n",
    "        result = result.transpose(0, 1).contiguous()  \n",
    "        return result\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for param in self.impl.parameters():\n",
    "            if param.dim() > 1:\n",
    "                nn.init.xavier_uniform_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: 2094312\n"
     ]
    }
   ],
   "source": [
    "vocab_size = tokenizer.vocab_size()\n",
    "embedding_size = 256\n",
    "\n",
    "enoder = TransformerEncoder(nn.TransformerEncoderLayer(d_model=256, nhead=16, \n",
    "                                                              dim_feedforward=512, dropout=0.3), num_layers=3)\n",
    "\n",
    "\n",
    "model = LanguageModel(vocab_size, embedding_size, enoder, emb_dropout=0.1)\n",
    "print('Params:', sum(t.numel() for t in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 2e-3\n",
    "EPOCH = 40\n",
    "reg_alpha = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=reg_alpha)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_tools import train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0m 30s | Epoch: 1 / 40 | T-Loss: 6.272 | Val-Loss: 6.088\n",
      "Time: 1m 0s | Epoch: 2 / 40 | T-Loss: 6.039 | Val-Loss: 5.731\n",
      "Time: 1m 29s | Epoch: 3 / 40 | T-Loss: 5.366 | Val-Loss: 4.747\n",
      "Time: 1m 59s | Epoch: 4 / 40 | T-Loss: 4.699 | Val-Loss: 4.413\n",
      "Time: 2m 28s | Epoch: 5 / 40 | T-Loss: 4.451 | Val-Loss: 4.231\n",
      "Time: 2m 58s | Epoch: 6 / 40 | T-Loss: 4.303 | Val-Loss: 4.088\n",
      "Time: 3m 27s | Epoch: 7 / 40 | T-Loss: 4.184 | Val-Loss: 3.962\n",
      "Time: 3m 57s | Epoch: 8 / 40 | T-Loss: 4.082 | Val-Loss: 3.859\n",
      "Time: 4m 26s | Epoch: 9 / 40 | T-Loss: 3.995 | Val-Loss: 3.771\n",
      "Time: 4m 56s | Epoch: 10 / 40 | T-Loss: 3.919 | Val-Loss: 3.693\n",
      "Time: 5m 25s | Epoch: 11 / 40 | T-Loss: 3.852 | Val-Loss: 3.629\n",
      "Time: 5m 54s | Epoch: 12 / 40 | T-Loss: 3.793 | Val-Loss: 3.564\n",
      "Time: 6m 24s | Epoch: 13 / 40 | T-Loss: 3.741 | Val-Loss: 3.508\n",
      "Time: 6m 53s | Epoch: 14 / 40 | T-Loss: 3.696 | Val-Loss: 3.461\n",
      "Time: 7m 22s | Epoch: 15 / 40 | T-Loss: 3.657 | Val-Loss: 3.414\n",
      "Time: 7m 52s | Epoch: 16 / 40 | T-Loss: 3.618 | Val-Loss: 3.384\n",
      "Time: 8m 21s | Epoch: 17 / 40 | T-Loss: 3.583 | Val-Loss: 3.335\n",
      "Time: 8m 51s | Epoch: 18 / 40 | T-Loss: 3.554 | Val-Loss: 3.313\n",
      "Time: 9m 20s | Epoch: 19 / 40 | T-Loss: 3.526 | Val-Loss: 3.280\n",
      "Time: 9m 50s | Epoch: 20 / 40 | T-Loss: 3.498 | Val-Loss: 3.254\n",
      "Time: 10m 19s | Epoch: 21 / 40 | T-Loss: 3.474 | Val-Loss: 3.226\n",
      "Time: 10m 49s | Epoch: 22 / 40 | T-Loss: 3.451 | Val-Loss: 3.205\n",
      "Time: 11m 18s | Epoch: 23 / 40 | T-Loss: 3.431 | Val-Loss: 3.182\n",
      "Time: 11m 47s | Epoch: 24 / 40 | T-Loss: 3.412 | Val-Loss: 3.154\n",
      "Time: 12m 16s | Epoch: 25 / 40 | T-Loss: 3.394 | Val-Loss: 3.138\n",
      "Time: 12m 46s | Epoch: 26 / 40 | T-Loss: 3.376 | Val-Loss: 3.113\n",
      "Time: 13m 15s | Epoch: 27 / 40 | T-Loss: 3.358 | Val-Loss: 3.104\n",
      "Time: 13m 45s | Epoch: 28 / 40 | T-Loss: 3.345 | Val-Loss: 3.085\n",
      "Time: 14m 14s | Epoch: 29 / 40 | T-Loss: 3.327 | Val-Loss: 3.072\n",
      "Time: 14m 44s | Epoch: 30 / 40 | T-Loss: 3.315 | Val-Loss: 3.053\n",
      "Time: 15m 13s | Epoch: 31 / 40 | T-Loss: 3.303 | Val-Loss: 3.039\n",
      "Time: 15m 42s | Epoch: 32 / 40 | T-Loss: 3.289 | Val-Loss: 3.026\n",
      "Time: 16m 11s | Epoch: 33 / 40 | T-Loss: 3.276 | Val-Loss: 3.010\n",
      "Time: 16m 41s | Epoch: 34 / 40 | T-Loss: 3.262 | Val-Loss: 2.998\n",
      "Time: 17m 10s | Epoch: 35 / 40 | T-Loss: 3.252 | Val-Loss: 2.986\n",
      "Time: 17m 39s | Epoch: 36 / 40 | T-Loss: 3.242 | Val-Loss: 2.974\n",
      "Time: 18m 8s | Epoch: 37 / 40 | T-Loss: 3.231 | Val-Loss: 2.956\n",
      "Time: 18m 38s | Epoch: 38 / 40 | T-Loss: 3.221 | Val-Loss: 2.947\n",
      "Time: 19m 7s | Epoch: 39 / 40 | T-Loss: 3.210 | Val-Loss: 2.932\n",
      "Time: 19m 37s | Epoch: 40 / 40 | T-Loss: 3.202 | Val-Loss: 2.929\n"
     ]
    }
   ],
   "source": [
    "model = train_loop(model,device, optimizer, train_loader, test_loader, epoch_value=EPOCH, plot_loss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k0splSYRDI3G"
   },
   "source": [
    "## Fit model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text(model, tokenizer, seq_begin):\n",
    "    eos_token = 3\n",
    "    max_steps_n = 40\n",
    "    \n",
    "    seed_tokens = tokenizer.encode([seq_begin])[0]\n",
    "    \n",
    "    for _ in range(max_steps_n):\n",
    "        in_batch = torch.tensor(seed_tokens).unsqueeze(0).to(device)\n",
    "        best_next_token = model(in_batch)[0, -1].argmax()\n",
    "        if best_next_token == eos_token:\n",
    "            break\n",
    "\n",
    "        seed_tokens.append(best_next_token)\n",
    "\n",
    "    return tokenizer.decode([seed_tokens])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'На уроке я проснулся от того, что умерлась в туалете и услышал какую то хуйню.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_text(model, tokenizer, \"На уроке я\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'story_model_trs.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lm_sent.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
