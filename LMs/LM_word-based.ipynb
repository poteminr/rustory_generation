{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HzETJPTeDI2l"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "# import transformers\n",
    "# from transformers import convert_bert_original_tf_checkpoint_to_pytorch\n",
    "# from transformers import BertTokenizer, BertModel, BertForMaskedLM, BertForQuestionAnswering, BertForPreTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WaS0OXNbDI2v"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pr6bFskwDI2y"
   },
   "source": [
    "## Load bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZhMxRcYDI2y",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# BERT_MODEL_PATH = \"rubert/\"\n",
    "# os.listdir(BERT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vkSBjUxJDI20"
   },
   "outputs": [],
   "source": [
    "# convert_bert_original_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(\n",
    "#     BERT_MODEL_PATH + 'bert_model.ckpt',\n",
    "# BERT_MODEL_PATH + 'bert_config.json','pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "582XnbGuDI22"
   },
   "outputs": [],
   "source": [
    "# model_path = \"rubert_pytorch/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARACNWvSDI24"
   },
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "# model = BertModel.from_pretrained(model_path);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4swSGSVDI25"
   },
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTSxoD8cDI25"
   },
   "outputs": [],
   "source": [
    "story_path = \"corpus/story_data.pkl\"\n",
    "with open(story_path, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iNrocaqPSifM"
   },
   "outputs": [],
   "source": [
    "STORY_VAL = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WYSlyCo2DI26"
   },
   "outputs": [],
   "source": [
    "data_batch = data[:STORY_VAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGg9K_qxDI27",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_flat = np.concatenate(data_batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oEJkiKHvDI28"
   },
   "outputs": [],
   "source": [
    "data_flat = list(map(str.lower, data_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FEp-Sn-7DI29"
   },
   "source": [
    "## Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hOzsyO2uDI2-"
   },
   "outputs": [],
   "source": [
    "vocab = set(data_flat)\n",
    "voc_len=len(vocab) + 1\n",
    "word_to_ix = {word: i+1 for i, word in enumerate(vocab)}\n",
    "word_to_ix[\"<pad>\"] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2YHh80eDI2-"
   },
   "outputs": [],
   "source": [
    "def get_samples(data):\n",
    "    input_seq = []\n",
    "    target_seq = []\n",
    "    \n",
    "    for story in data:\n",
    "        input_seq.append(np.array(story[:-1]))\n",
    "        target_seq.append(np.array(story[1:]))\n",
    "    \n",
    "    return np.array(input_seq), np.array(target_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5PzKdF6qDI2_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_seq, target_seq = get_samples(data_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DFKtxGBwDI3A"
   },
   "outputs": [],
   "source": [
    "for i in range(len(data_batch)):\n",
    "    input_seq[i] = torch.tensor([word_to_ix[word.lower()] for word in input_seq[i]])\n",
    "    target_seq[i] = torch.tensor([word_to_ix[word.lower()] for word in target_seq[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_IbNw60qDI3B"
   },
   "outputs": [],
   "source": [
    "input_seq = torch.nn.utils.rnn.pad_sequence(input_seq, batch_first=True,padding_value=0)\n",
    "target_seq = torch.nn.utils.rnn.pad_sequence(target_seq, batch_first=True, padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CrxCXTCVez9s"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "data2train = torch.utils.data.TensorDataset(input_seq, target_seq)\n",
    "train_loader = torch.utils.data.DataLoader(data2train, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gGV-DFHF7TWQ",
    "outputId": "2bcad7e2-2a9a-4286-87e4-06ead1f5bf83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 442])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LtK1XGqHDI3C"
   },
   "source": [
    "## Init Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4tee-UumDI3C"
   },
   "outputs": [],
   "source": [
    "# def get_bert_embed_matrix(model):\n",
    "    \n",
    "#     bert_embeddings = list(model.children())[0]\n",
    "#     bert_word_embeddings = list(bert_embeddings.children())[0]\n",
    "#     mat = bert_word_embeddings.weight.data.numpy()\n",
    "#     return torch.tensor(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ufRblhTSDI3D"
   },
   "outputs": [],
   "source": [
    "# matrix = get_bert_embed_matrix(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J58A4sQADI3E"
   },
   "outputs": [],
   "source": [
    "# def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "#     num_embeddings, embedding_dim = weights_matrix.size()\n",
    "#     emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "#     emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "#     if non_trainable:\n",
    "#         emb_layer.weight.requires_grad = False\n",
    "\n",
    "#     return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Chp0UCPDDI3F"
   },
   "source": [
    "## Init Language Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rl1iMxz4DI3F"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "#         self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size*2)\n",
    "\n",
    "\n",
    "        self.lstm = nn.GRU(hidden_size*2, hidden_size, n_layers, batch_first=True,\n",
    "                          bidirectional=False) \n",
    "        \n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.fc_1 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_2 = nn.Linear(hidden_size // 2, output_size)\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        # x = x.to(device)\n",
    "        hidden = self.init_hidden(batch_size).to(device)\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "#         print(x.size())\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        out = out.contiguous().view(-1, self.hidden_size)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc_1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc_2(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k0splSYRDI3G"
   },
   "source": [
    "## Fit model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aezvz1arDI3G"
   },
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "hidden_size = 240\n",
    "n_layers = 2\n",
    "lr = 0.002\n",
    "print_every = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AEDjE79bDI3H"
   },
   "outputs": [],
   "source": [
    "model = Model(voc_len, hidden_size, voc_len, n_layers)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MyI-9yapQtJN"
   },
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0UC51pG9DI3H",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss_accum = 0\n",
    "    for i_step, (input_s, target_s) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "#     hidden = model.init_hidden().cuda()\n",
    "        target_s = target_s.to(device)\n",
    "        input_s = input_s.to(device)\n",
    "    \n",
    "        output, _ = model(input_s)\n",
    "        loss = criterion(output, target_s.view(-1).long())\n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "    \n",
    "        loss_accum += loss\n",
    "        del input_s\n",
    "        del target_s\n",
    "    \n",
    "\n",
    "\n",
    "    ave_loss = loss_accum / i_step\n",
    "    if epoch % print_every == 0:\n",
    "        print('Time: %s | Epoch: %d / %d%% | Loss: %.4f' % (time_since(start), epoch, n_epochs, ave_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bbXXuKF-DI3I"
   },
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Uv2O-9zDI3I"
   },
   "outputs": [],
   "source": [
    "ix_to_word = {v:k for k, v in word_to_ix.items()}\n",
    "def predict(model, words):\n",
    "    words = np.array([[word_to_ix[c] for c in words]])\n",
    "\n",
    "    words = torch.from_numpy(words[0])\n",
    "    words = words.to(device)\n",
    "    words = words.view(1, -1)\n",
    "    \n",
    "    out, hidden = model(words)\n",
    "\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    char_ind = torch.max(prob, dim=0)[1].item()\n",
    "\n",
    "    return ix_to_word[char_ind], hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9XCrNXJnDI3J"
   },
   "outputs": [],
   "source": [
    "def sample(model, out_len, start='я'):\n",
    "    model.eval() \n",
    "    words_data = start.lower().split()\n",
    "    \n",
    "    size = out_len - len(words_data)\n",
    "\n",
    "    for ii in range(size):\n",
    "        word, h = predict(model, words_data)\n",
    "        words_data.append(word)\n",
    "\n",
    "    return ' '.join(words_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UHJSBi2JDI3K"
   },
   "source": [
    "## Generated Story "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YsZqsMIfDI3K",
    "outputId": "c0bed1f5-f11c-41a7-eb71-0977e8aaabeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'да с моем был состоялся кошек и заметили со страху позвали моя водитель использует один много рандомному каждой человек взяли'"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(model, 20, \"Да\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lm_sent.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
