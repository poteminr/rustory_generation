{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from transformers import convert_bert_original_tf_checkpoint_to_pytorch\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, BertForQuestionAnswering, BertForPreTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# BERT_MODEL_PATH = \"rubert/\"\n",
    "# os.listdir(BERT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_bert_original_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(\n",
    "#     BERT_MODEL_PATH + 'bert_model.ckpt',\n",
    "# BERT_MODEL_PATH + 'bert_config.json','pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"rubert_pytorch/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.tokenization_utils:Model name 'rubert_pytorch/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'rubert_pytorch/' is a path or url to a directory containing tokenizer files.\n",
      "INFO:transformers.tokenization_utils:Didn't find file rubert_pytorch/added_tokens.json. We won't load it.\n",
      "INFO:transformers.tokenization_utils:Didn't find file rubert_pytorch/special_tokens_map.json. We won't load it.\n",
      "INFO:transformers.tokenization_utils:Didn't find file rubert_pytorch/tokenizer_config.json. We won't load it.\n",
      "INFO:transformers.tokenization_utils:loading file rubert_pytorch/vocab.txt\n",
      "INFO:transformers.tokenization_utils:loading file None\n",
      "INFO:transformers.tokenization_utils:loading file None\n",
      "INFO:transformers.tokenization_utils:loading file None\n",
      "INFO:transformers.configuration_utils:loading configuration file rubert_pytorch/config.json\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file rubert_pytorch/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertModel.from_pretrained(model_path);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_path = \"story_data.pkl\"\n",
    "with open(story_path, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = data[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_flat = np.concatenate(new, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flat = list(map(str.lower, data_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['п19', 'как'], 'дурачок'), (['как', 'дурачок'], 'поехал'), (['дурачок', 'поехал'], 'к')]\n"
     ]
    }
   ],
   "source": [
    "trigrams = [([data_flat[i], data_flat[i + 1]], data_flat[i + 2])\n",
    "            for i in range(len(data_flat) - 2)]\n",
    "chunk_len=len(trigrams)\n",
    "print(trigrams[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(data_flat)\n",
    "voc_len=len(vocab)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp=[]\n",
    "tar=[]\n",
    "for context, target in trigrams:\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        inp.append(context_idxs)\n",
    "        targ = torch.tensor([word_to_ix[target]], dtype=torch.long)\n",
    "        tar.append(targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Language Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embed_matrix(model):\n",
    "    \n",
    "    bert_embeddings = list(model.children())[0]\n",
    "    bert_word_embeddings = list(bert_embeddings.children())[0]\n",
    "    mat = bert_word_embeddings.weight.data.numpy()\n",
    "    return torch.tensor(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = get_bert_embed_matrix(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "    num_embeddings, embedding_dim = weights_matrix.size()\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "#         self.encoder, input_size, hidden_size = create_emb_layer(matrix, True)\n",
    "\n",
    "        self.gru = nn.GRU(hidden_size*2, hidden_size, n_layers, batch_first=True,\n",
    "                          bidirectional=False)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden().cuda()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[c].cuda(), hidden)\n",
    "        loss += criterion(output, target[c].cuda())\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data.item() / chunk_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 15s (1 0%) 8.1147]\n",
      "[0m 30s (2 0%) 7.6463]\n",
      "[0m 45s (3 0%) 7.0041]\n",
      "[1m 0s (4 0%) 6.3052]\n",
      "[1m 15s (5 0%) 5.7327]\n",
      "[1m 31s (6 0%) 5.2069]\n",
      "[1m 46s (7 0%) 4.6993]\n",
      "[2m 1s (8 0%) 4.1808]\n",
      "[2m 16s (9 0%) 3.6588]\n",
      "[2m 31s (10 0%) 3.1496]\n",
      "[2m 46s (11 0%) 2.6804]\n",
      "[3m 1s (12 0%) 2.2705]\n",
      "[3m 16s (13 0%) 1.9168]\n",
      "[3m 31s (14 0%) 1.6125]\n",
      "[3m 47s (15 0%) 1.3502]\n",
      "[4m 2s (16 0%) 1.1244]\n",
      "[4m 17s (17 0%) 0.9319]\n",
      "[4m 32s (18 0%) 0.7681]\n",
      "[4m 47s (19 0%) 0.6303]\n",
      "[5m 2s (20 0%) 0.5153]\n",
      "[5m 17s (21 0%) 0.4194]\n",
      "[5m 32s (22 0%) 0.3402]\n",
      "[5m 47s (23 0%) 0.2754]\n",
      "[6m 3s (24 0%) 0.2227]\n",
      "[6m 18s (25 0%) 0.1804]\n",
      "[6m 33s (26 0%) 0.1464]\n",
      "[6m 48s (27 0%) 0.1191]\n",
      "[7m 3s (28 0%) 0.0973]\n",
      "[7m 18s (29 0%) 0.0800]\n",
      "[7m 33s (30 0%) 0.0662]\n",
      "[7m 48s (31 0%) 0.0552]\n",
      "[8m 3s (32 0%) 0.0463]\n",
      "[8m 18s (33 0%) 0.0392]\n",
      "[8m 34s (34 0%) 0.0333]\n",
      "[8m 49s (35 0%) 0.0286]\n",
      "[9m 4s (36 0%) 0.0248]\n",
      "[9m 19s (37 0%) 0.0217]\n",
      "[9m 34s (38 0%) 0.0192]\n",
      "[9m 49s (39 0%) 0.0172]\n",
      "[10m 4s (40 0%) 0.0154]\n",
      "[10m 19s (41 0%) 0.0140]\n",
      "[10m 34s (42 0%) 0.0127]\n",
      "[10m 49s (43 0%) 0.0117]\n",
      "[11m 5s (44 0%) 0.0108]\n",
      "[11m 20s (45 0%) 0.0100]\n",
      "[11m 35s (46 0%) 0.0094]\n",
      "[11m 50s (47 0%) 0.0088]\n",
      "[12m 5s (48 0%) 0.0082]\n",
      "[12m 20s (49 0%) 0.0078]\n",
      "[12m 36s (50 0%) 0.0074]\n",
      "[12m 51s (51 0%) 0.0071]\n",
      "[13m 6s (52 0%) 0.0067]\n",
      "[13m 22s (53 0%) 0.0065]\n",
      "[13m 37s (54 0%) 0.0062]\n",
      "[13m 52s (55 0%) 0.0060]\n",
      "[14m 8s (56 0%) 0.0058]\n",
      "[14m 23s (57 0%) 0.0056]\n",
      "[14m 38s (58 0%) 0.0055]\n",
      "[14m 53s (59 0%) 0.0053]\n",
      "[15m 9s (60 0%) 0.0052]\n",
      "[15m 24s (61 0%) 0.0051]\n",
      "[15m 39s (62 0%) 0.0049]\n",
      "[15m 54s (63 0%) 0.0048]\n",
      "[16m 9s (64 0%) 0.0047]\n",
      "[16m 25s (65 0%) 0.0047]\n",
      "[16m 40s (66 0%) 0.0046]\n",
      "[16m 55s (67 0%) 0.0045]\n",
      "[17m 11s (68 0%) 0.0044]\n",
      "[17m 26s (69 0%) 0.0044]\n",
      "[17m 41s (70 0%) 0.0043]\n",
      "[17m 56s (71 0%) 0.0042]\n",
      "[18m 12s (72 0%) 0.0042]\n",
      "[18m 27s (73 0%) 0.0041]\n",
      "[18m 42s (74 0%) 0.0041]\n",
      "[18m 57s (75 0%) 0.0040]\n",
      "[19m 12s (76 0%) 0.0040]\n",
      "[19m 27s (77 0%) 0.0039]\n",
      "[19m 42s (78 0%) 0.0039]\n",
      "[19m 57s (79 0%) 0.0038]\n",
      "[20m 13s (80 1%) 0.0038]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 80\n",
    "print_every = 1\n",
    "plot_every = 4\n",
    "hidden_size = 120\n",
    "n_layers = 1\n",
    "lr = 0.015\n",
    "\n",
    "decoder = RNN(voc_len, hidden_size, voc_len, n_layers)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "if(train_on_gpu):\n",
    "    decoder.cuda()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(inp,tar)       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd6cbfd43c8>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prime_str, predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden().cuda()\n",
    "\n",
    "    for p in range(predict_len):\n",
    "        \n",
    "        prime_input = torch.tensor([word_to_ix[w] for w in prime_str.split()], dtype=torch.long).cuda()\n",
    "        inp = prime_input[-2:] \n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        predicted_word = list(word_to_ix.keys())[list(word_to_ix.values()).index(top_i)]\n",
    "        prime_str += \" \" + predicted_word\n",
    "#         inp = torch.tensor(word_to_ix[predicted_word], dtype=torch.long)\n",
    "\n",
    "    return prime_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "друг купил две шавы и заскринил оплату теперь ходим и покупаем шаурму по скрину включаем дурочку делаем так\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('друг купил', 16, temperature=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
